## Report Interaction Logs

Reporting full interaction logs, that is all prompts and responses, is especially important when reporting a study targeting commercial SaaS solutions based on LLMs (e.g., ChatGPT) or novel tools that integrate LLMs via cloud APIs.
Given that commercial LLMs and LLM-based tools are evolving systems (minor upgrades of a major version are likely to be [deployed frequently](https://arxiv.org/abs/2307.09009)) and that they [behave non-deterministically](https://152334h.github.io/blog/non-determinism-in-gpt-4/) even with a temperature of 0, reporting the prompts and model versions alone will not be enough to enable reproducibility.
Even for models such as [Llama](https://www.llama.com/) that researchers can host and configure themselves, reaching complete determinism is challenging.
While decoding strategies and parameters can be fixed (e.g., by defining seeds, using deterministic decoding strategies, setting temperature to 0, etc.), non-determinism can also arise from batching, input preprocessing, and floating point arithmetic on GPUs.
Thus, for complete transparency, a researcher should report the answers generated by the LLM or LLM-based tool in the context of the presented study.
In this sense, the way an LLM has to be treated is similar to the way a human participant in an interview would be treated, because both the human and the LLM might provide different answers if presented with the same questions at different times.
The difference is that, while for human participants conversations often cannot be reported due to confidentiality, LLM conversations can.

### Recommendations per Study Type

**TODO:** Connect guideline to study types and for each type have bullet point lists with information that MUST, SHOULD, or MAY be reported (usage of those terms according to [RFC 2119](https://www.rfc-editor.org/rfc/rfc2119)).
